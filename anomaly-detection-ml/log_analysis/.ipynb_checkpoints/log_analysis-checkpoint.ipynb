{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a44ed88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: data/unstructured/HDFS/HDFS_2k.log\n",
      "Processed 50.0% of log lines.\n",
      "Processed 100.0% of log lines.\n",
      "Parsing done. [Time taken: 0:00:00.328635]\n",
      "Loading data/structured/HDFS/HDFS_2k.log_structured.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from log_parser import Drain\n",
    "\n",
    "log_file_path = 'data/unstructured/HDFS/'\n",
    "label_file_name = 'data/unstructured/HDFS/anomaly_label.csv'\n",
    "unstructured_log_filename = 'HDFS_2k.log'\n",
    "structured_log_file_path = 'data/structured/HDFS/'\n",
    "structured_log_filename = 'HDFS_2k.log_structured.csv'\n",
    "\n",
    "\n",
    "def parseLog(log_file_path, log_file_name, structured_log_file_path, log_type):\n",
    "    if log_type == 'HDFS':\n",
    "        log_format = '<Date> <Time> <Pid> <Level> <Component>: <Content>'\n",
    "\n",
    "    # Regular expression list for optional preprocessing (default: [])\n",
    "    regex      = [\n",
    "        r'blk_(|-)[0-9]+' , # block id\n",
    "        r'(/|)([0-9]+\\.){3}[0-9]+(:[0-9]+|)(:|)', # IP\n",
    "        r'(?<=[^A-Za-z0-9])(\\-?\\+?\\d+)(?=[^A-Za-z0-9])|[0-9]+$', # Numbers\n",
    "    ]\n",
    "    st         = 0.5  # Similarity threshold\n",
    "    depth      = 4  # Depth of all leaf nodes\n",
    "\n",
    "    parser = Drain.LogParser(log_format, indir=log_file_path, outdir=structured_log_file_path,  depth=depth, st=st, rex=regex)\n",
    "    parser.parse(log_file_name)\n",
    "\n",
    "## parse the logs - convert unstructured to structured log\n",
    "parseLog(log_file_path, unstructured_log_filename, structured_log_file_path, 'HDFS')\n",
    "    \n",
    "\n",
    "## read structured log \n",
    "print(\"Loading\", structured_log_file_path+structured_log_filename)\n",
    "structured_log = pd.read_csv(structured_log_file_path+structured_log_filename, engine='c', na_filter=False, memory_map=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fd0e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       BlockId EventSequence  Label\n",
      "0        blk_38865049064139660    [dc2c74b7]      0\n",
      "1     blk_-6952295868487656571    [dc2c74b7]      0\n",
      "2      blk_7128370237687728475    [5d5de21c]      0\n",
      "3      blk_8229193803249955061    [dc2c74b7]      0\n",
      "4     blk_-6670958622368987959    [dc2c74b7]      0\n",
      "...                        ...           ...    ...\n",
      "2195   blk_4198733391373026104    [09a53393]      0\n",
      "2196  blk_-5815145248455404269    [e3df2680]      0\n",
      "2197   blk_-295306975763175640    [09a53393]      0\n",
      "2198   blk_5225719677049010638    [dc2c74b7]      0\n",
      "2199   blk_4343207286455274569    [09a53393]      0\n",
      "\n",
      "[2200 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_split_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10357/2029018064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Split train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m (x_train, y_train), (x_test, y_test) = _split_data(data_df['EventSequence'].values, \n\u001b[0m\u001b[1;32m     27\u001b[0m     data_df['Label'].values, train_ratio, split_type)\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_split_data' is not defined"
     ]
    }
   ],
   "source": [
    "# print(struct_log)\n",
    "\n",
    "# Create a map of BlockId vs the EventSequence. \n",
    "data_dict = OrderedDict()\n",
    "\n",
    "for idx, row in structured_log.iterrows():\n",
    "    block_ids = set(re.findall(r'(blk_-?\\d+)', row['Content']))\n",
    "    for block in block_ids:\n",
    "        if not block in data_dict:\n",
    "            data_dict[block] = []\n",
    "        data_dict[block].append(row['EventId'])\n",
    "data_df = pd.DataFrame(list(data_dict.items()), columns=['BlockId', 'EventSequence'])\n",
    "\n",
    "\n",
    "# Add anomaly label to the data tagged to block id\n",
    "label_data = pd.read_csv(label_file_name, engine='c', na_filter=False, memory_map=True)\n",
    "label_data = label_data.set_index('BlockId')\n",
    "label_dict = label_data['Label'].to_dict()\n",
    "data_df['Label'] = data_df['BlockId'].apply(lambda x: 1 if label_dict[x] == 'Anomaly' else 0)\n",
    "\n",
    "print(data_df)\n",
    "data_df.to_csv('data_instances.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split train and test data\n",
    "# (x_train, y_train), (x_test, y_test) = _split_data(data_df['EventSequence'].values, \n",
    "#     data_df['Label'].values, train_ratio, split_type)\n",
    "\n",
    "# print(y_train.sum(), y_test.sum())\n",
    "\n",
    "\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = dataloader.load_HDFS(...)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## apply ML to it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
